{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Transcrição dos áudios"
      ],
      "metadata": {
        "id": "z0cnCtVOPe24"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bibliotecas e Funcionalidades iniciais para transcrição:\n",
        "\n",
        "Whisper: É um modelo de transcrição de áudio desenvolvido pela OpenAI. Ele é utilizado para converter áudio em texto, suportando múltiplos idiomas e podendo ser aplicado em tarefas de reconhecimento de fala (speech-to-text).\n",
        "\n",
        "PyTorch: É uma biblioteca de machine learning de código aberto amplamente utilizada para desenvolvimento e treinamento de modelos de inteligência artificial. Ela é conhecida pela sua facilidade de uso e flexibilidade, permitindo a criação de redes neurais complexas de forma eficiente.\n",
        "\n",
        "\n",
        "CUDA (Compute Unified Device Architecture) é uma plataforma de computação paralela e uma interface de programação de aplicativos (API) criada pela NVIDIA. Ela permite que desenvolvedores utilizem o poder de processamento de GPUs (unidades de processamento gráfico) para realizar cálculos e tarefas computacionais que não estão restritas ao processamento gráfico tradicional.\n",
        "\n",
        "Essas bibliotecas funcionam de forma integrada, e o PyTorch com suporte a CUDA permite o uso de GPUs para acelerar o treinamento e a inferência de modelos, o que é especialmente útil em tarefas que envolvem grandes quantidades de dados, como transcrição de áudio com Whisper.\n"
      ],
      "metadata": {
        "id": "LuuAZfkuQxpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar o Whisper e o PyTorch com suporte a CUDA\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Importar as bibliotecas necessárias\n",
        "import whisper # Biblioteca para transcrição de áudio\n",
        "import torch # É uma biblioteca de machine learning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qx51Q1N5Smxd",
        "outputId": "d772819b-7497-4f99-862c-0a69110aa4a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-2_3_9pcf\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-2_3_9pcf\n",
            "  Resolved https://github.com/openai/whisper.git to commit 279133e3107392276dc509148da1f41bfb532c7e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.4.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.5)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.5.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting triton>=2.0.0 (from openai-whisper==20231117)\n",
            "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper==20231117) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2024.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802819 sha256=620b3444e6c4bac5288bf1874a7983754c5813be2e92ada5a5104972d02a21a2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hp1sljze/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: triton, tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20231117 tiktoken-0.7.0 triton-3.0.0\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar se o ambiente está utilizando GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Dispositivo em uso: {device}\")\n",
        "\n",
        "#Função para carregar um ou mais arquivo de áudio e realizar a transcrição\n",
        "# Carregar o modelo 'medium' do Whisper\n",
        "model = whisper.load_model('medium', device=device)\n",
        "\n",
        "while True:\n",
        "    # Solicitar o nome do arquivo de áudio\n",
        "    audio_file = input(\"Digite o nome do arquivo de áudio (com extensão): \")\n",
        "\n",
        "    # Transcrever o arquivo de áudio com as configurações otimizadas\n",
        "    result = model.transcribe(audio_file, fp16=torch.cuda.is_available())\n",
        "\n",
        "    # Exibir o texto transcrito\n",
        "    print(\"\\nTexto transcrito:\")\n",
        "    print(result['text'])\n",
        "\n",
        "    # Salvar a transcrição em um arquivo .txt\n",
        "    txt_file = audio_file.rsplit('.', 1)[0] + '.txt'  # Substitui a extensão por .txt\n",
        "    with open(txt_file, 'w', encoding='utf-8') as f:\n",
        "        f.write(result['text'])\n",
        "    print(f\"\\nTranscrição salva em: {txt_file}\")\n",
        "\n",
        "    # Perguntar se o usuário deseja transcrever outro arquivo\n",
        "    continuar = input(\"\\nDeseja transcrever outro arquivo? (sim/não): \").strip().lower()\n",
        "    if continuar != 'sim':\n",
        "        print(\"Encerrando o programa.\")\n",
        "        break"
      ],
      "metadata": {
        "id": "FOKNRbGP6kSR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e63966e-806b-4a3a-da65-4819f33a01ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo em uso: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:35<00:00, 43.5MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Digite o nome do arquivo de áudio (com extensão): 2874830.wav\n",
            "\n",
            "Texto transcrito:\n",
            " Oi, bom dia, falo com o Sr. Pedro? Bom dia, sou eu mesmo. Sr. Pedro, me chamo Beatriz, falo da TOTS, tudo bem? Da TOTS? Isso. Certo. Tudo bem, Sr. Pedro? Tudo bom, é? Que bom. O Sr. seria o responsável ainda pelo DP e utiliza o sistema na empresa Complexo Brasil? Sim, o responsável pelo DP é a Ana Carla. O Sr. seria pelo RH? Porque pra mim aqui tá como um DP, o Sr. É, mas o responsável no DP é a Ana Carla. Ah, entendi. O Sr. não seria responsável então? Não, eu trabalho com o sistema, sim, ajudo, faz as foras de pagamento, mas a coordenadora é a Ana Carla. Ah, entendi. É que eu preciso fazer um acompanhamento com o responsável pra gente saber como que tá aí a experiência de vocês. Será que ela tem dois minutinhos pra falar comigo agora? É a Ana Carla, né? É a Ana Carla. Tá bom. A Ana Carla da TOTS. Vou transmitir pra ela, 47-06. Obrigada. Ok. R.H. Ana Carla. Bom dia, Ana Carla. Beatriz da TOTS falando, tudo bem? Bom dia, Beatriz. Tudo bem você? Tudo bem, obrigada. A Sara Ana Carla seria responsável pela área e utiliza o sistema TOTS na empresa? Isso. Condomínio do Bloco C, do Brasil, 21, né? Tá. Meu contato é bem rápido, Sara Ana. Eu preciso fazer um acompanhamento só pra saber como tá aí a experiência e satisfação de vocês? Sim. A Sara Ana, eu preciso fazer um acompanhamento só pra saber como tá aí a experiência e satisfação de vocês? Esse acompanhamento é feito pelo método de NPS, então a Sara vai ler somente de 0 a 10 a marca TOTS e alguns pontos específicos que eu preciso perguntar. Dura dois minutinhos, tá bom? Tá ok. Só confirmando então, CNPJ, é o 07354754, meu contra é 99, ok? Então, na verdade é o do Bloco C? Isso, esse eu tô falando em relação ao Bloco C do Brasil, 21, tá? Tá, é porque aqui eu cuido com... Tem outros CNPJ, esse é um que eu não mexo. Ah, entendi, mas a Sara utiliza o sistema. Eu utilizo. Tá, não tem problema, tá bom? O e-mail que eu tenho aqui só pra confirmar, Dara, é o dpbr.com.br, seria a senhora também? Não. Oh, seria da senhora? Não. O meu é Ana Carro, ponto Pereira, da Arroba Melha. Ah, entendi, então vou deixar esses aqui. Eu tenho os dois, aí eu atualizo o comando assim. Obrigada pela atualização. Numa escala de 0 a 10, Sara Ana, qual a probabilidade da Sara recomendar a TOTS, ó amiga ou colega hoje? 10. Tem algum comentário que a Sara gostaria de deixar sobre a nota? Não, o sistema é muito completo, muito bom, eu gosto dele. O sistema é muito completo, tá. Algo mais? Não. Tá, pra gente aprofundar um pouquinho mais na melhoria, agora eu vou falar alguns pontos específicos e peço que a Sara Valir também somente 0 a 10 caso tenha contato, se não tiver, não precisa avaliar, tá bom? Falando do suporte técnico, como a Sara Valir a agilidade quando vocês precisam de um atendimento do suporte? Desculpa, como é que se chama? Beatriz. Beatriz, 6. 6, tá. E o atendimento do agente do suporte, né, os analistas em geral que lidam com vocês? A gente tem uma pessoa específica aqui só, né? Eu continuo 6. É difícil nosso contato. Tá bom. Tá bom. Falando em relação ao atendimento do comercial referente ao Executivo de Vendas, né? Esse eu não tenho contato. Não, tudo bem. Custo e valor dos produtos contratados? A Sara tem contato. Atendimento da administração financeira o referente a boletos e negociações caso precisem? Também não mexo. Satisfação com a implantação do software? A Sara estava quando o sistema foi implantado ou não? Não, tava não. Hoje o sistema entrega o benefício que vocês precisam? Entrega totalmente, parcialmente ou não entrega? Entrega totalmente. Tá. Como foi a experiência da senhora com a atualização do software? Vocês já atualizaram? A Sara como usuária final sente alguma diferença? Não, não. Não, não atualização não é a gente que faz aqui. Mas a Sara como usuária final tem ciência que foi atualizada e sente alguma diferença? Tem, tem. Tá. Então a Sara consegue avaliar de 0 a 10? 9? 9, tá. Para finalizar a PESCA a Sara vai ler de 0 a 10 o atendimento realizado pela TOTUS Unidade de Brasília, é responsável aí por vocês. O atendimento deles. 7. Tá. Sabe se as perguntas a Sara tem algum comentário final, Farahana? Não, não. Tá bom, esse acompanhamento ele ocorre a cada 6 meses, tá? Passando o período retornamos o contato. A Sara tem alguma dúvida, algum comentário final? Não, não, obrigada. Tá. Teria alguma empresa aqui que gostaria de indicar para a gente? No momento não, não me recordo. Tá. Tudo bem, então eu agradeço que a Sara tenha um ótimo dia e bom trabalho, Sara Ana. Tchau, tchau. Obrigada.\n",
            "\n",
            "Transcrição salva em: 2874830.txt\n",
            "\n",
            "Deseja transcrever outro arquivo? (sim/não): sim\n",
            "Digite o nome do arquivo de áudio (com extensão): 2962046.wav\n",
            "\n",
            "Texto transcrito:\n",
            " Oi, Cláudio. Bom dia. Lilia da TOTUS, tudo bem? Oi, tudo bem. Que ótimo. Sou do Departamento Voz do Cliente. A gente entrou em contato com o senhor no passado para fazer o NPS, uma avaliação geral. Estou ligando novamente. Tem dois minutos? Sim. Ok. Só vou confirmar o final do CNPJ da empresa Baterias Krau, que é o 2000 contra 00. Final. Confirma? Isso. Confirma. Iniciando então, de uma escala 0 a 10, qual a probabilidade do senhor recomendar a TOTUS a alguém hoje no geral? 8. 8. Suporte técnico ou nota para agilidade nos processos? 8. 8. E o atendimento em si dos agentes? Atendimento? Em si dos agentes do suporte? Na verdade, eu sou só atendido por uma pessoa, 8 também. Ah, certo. Tem contato com o Comercial Executivo de Vendas? Não. Não? Consegue avaliar custos e os valores dos produtos contratados? Ah, consigo, assim, mas tem uma certa dificuldade nos outros módulos que não utilizo, né? Mas acho que 8, no meu caso 8. O senhor é do Departamento Pessoal, né? Isso. Atendimento do Administrativo Financeiro que emite os boletos, faz as negociações? Não tenho contato. Não tem contato, mas três perguntas. O problema que vocês utilizam, está atendendo à necessidade da empresa total, parcial ou não atende? Total. Total. Uma nota para as atualizações que ocorrem nele? A atualização tem um pouco mais de dificuldade, vou dar nota 6. Muita dificuldade. Nota 6. E a última pergunta para avaliar a unidade TOTOS de Bauru. Tem contato com ele? Pouco contato, 7. 7. Gostaria de comentar alguma das perguntas que eu fiz? A questão de atualização aí que foi aqui, eu dei a nota menor. Eu sei que nós temos um problema interno, que seria o meu TI que às vezes não fica muito... Eu gostaria, se possível, de receber um e-mail indicado à atualização. Notificar, certo. Notificar, isso. E não recebe? Será que é só o TI que recebe aí da empresa? Então, eu não sei se ele recebe também. Mas se chegasse para mim, eu tenho como cobrar ele, entendeu? Sim. Tá. Coloquei nessa observação 6 aqui que você tem dificuldade com as atualizações e gostaria de receber uma notificação. Tá. E que mais? Não, só. Como observação, só. Tá bem, então. É isso, Cláudio. Eu agradeço a sua atenção. Ano que vem, te ligue de novo. Tenha um ótimo dia. Tá bom, então. Obrigado, igualmente. Tchau, tchau.\n",
            "\n",
            "Transcrição salva em: 2962046.txt\n",
            "\n",
            "Deseja transcrever outro arquivo? (sim/não): não\n",
            "Encerrando o programa.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análise de Sentimento para Classificação"
      ],
      "metadata": {
        "id": "HFMDTquPQqrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk # Importar a biblioteca NLTK (Natural Language Toolkit) em Python.\n",
        "from sklearn.model_selection import train_test_split # Essa função é usada para dividir um conjunto de dados em subconjuntos de treino e teste de forma aleatória\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB # classificadores\n",
        "from sklearn.metrics import accuracy_score # calcula a precisão (acurácia) de um modelo de classificação\n",
        "import pickle # serializar e salvar objetos Python em arquivos e também para carregar esses objetos de volta para a memória\n",
        "from nltk.corpus import stopwords # Da biblioteca nltk.corpus, ela contém uma lista de palavras irrelevantes (como \"o\", \"a\", \"e\") que são frequentemente removidas\n",
        "from nltk.stem import SnowballStemmer # Da biblioteca nltk, o stemmer é usado para reduzir palavras ao seu radical, removendo sufixos ou prefixos\n",
        "from sklearn.feature_extraction.text import CountVectorizer # Essa classe converte um conjunto de documentos em uma matriz de bag-of-words, essencial para transformar texto em dados numéricos para ML\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ],
      "metadata": {
        "id": "mGdgKdcOAAua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# carregar dataset público com série de frases e sentimentos do twitter já calssificados para treinar o modelo\n",
        "# disponível https://www.kaggle.com/datasets/gazprom/anlise-de-sentimentos-pt-br\n",
        "data = pd.read_csv(\"df_analise_sentimento.csv\", encoding='latin1') # adiciona o parâmetro encoding e define como latin1\n",
        "print(data.shape)\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "Ukk-xVYsAMqo",
        "outputId": "25582e3b-fdca-458c-9fe3-f22350152b9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2996, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Sentence Sentiment\n",
              "0  Os pedidos de produtos de processo são para a ...   neutral\n",
              "1  Grupo Intertek anuncia atualização estratégica...   neutral\n",
              "2  Barclays contrata o novo diretor de operações ...   neutral\n",
              "3  A divisão de private equity do FL Group admini...   neutral\n",
              "4  Pode ser qualquer um de nÃ³s a qualquer moment...   neutral"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d9c3a9fa-8b54-4f13-9ef1-015b8cd64c1a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Os pedidos de produtos de processo são para a ...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Grupo Intertek anuncia atualização estratégica...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Barclays contrata o novo diretor de operações ...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A divisão de private equity do FL Group admini...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pode ser qualquer um de nÃ³s a qualquer moment...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9c3a9fa-8b54-4f13-9ef1-015b8cd64c1a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d9c3a9fa-8b54-4f13-9ef1-015b8cd64c1a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d9c3a9fa-8b54-4f13-9ef1-015b8cd64c1a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-99ad785d-1d85-4403-b5e3-84c285f6678e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-99ad785d-1d85-4403-b5e3-84c285f6678e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-99ad785d-1d85-4403-b5e3-84c285f6678e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 2996,\n  \"fields\": [\n    {\n      \"column\": \"Sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2154,\n        \"samples\": [\n          \"As autoridades da cidade de Grapevine em setembro aprovaram US $ 35 milh\\u00f5es em descontos e subs\\u00eddios fiscais para a expans\\u00e3o.\",\n          \"Lucros das empresasMeggitt atingidos pelos fracos mercados energ\\u00e9tico e militar\",\n          \"A CompTel, um fornecedor do software Sistema de Suporte a Opera\\u00e7\\u00f5es Din\\u00e2micas (OSS), foi selecionado pela Orascom Telecom (OTH) como parceiro para solu\\u00e7\\u00f5es de provisionamento e ativa\\u00e7\\u00e3o para servi\\u00e7os m\\u00f3veis.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"neutral\",\n          \"positive\",\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info() # exibir um resumo sobre o DataFrame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzbTGW15CcwI",
        "outputId": "148821aa-fab6-4bc9-b3c5-5c1113f5002c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2996 entries, 0 to 2995\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   Sentence   2996 non-null   object\n",
            " 1   Sentiment  2996 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 46.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.Sentiment.value_counts() # contar a frequência de cada valor único na coluna Sentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "PwP8O1ZyCeM1",
        "outputId": "ab581452-4014-44e3-fab8-7ca8063ca92a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment\n",
              "neutral     1000\n",
              "positive     999\n",
              "negative     997\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>997</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.Sentence[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wahOY50_Cf3P",
        "outputId": "46b66cf4-1a46-4b55-bc54-bbab37f8a1e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Os pedidos de produtos de processo são para a instalação de equipamentos de filtração de separação em três projetos de gasoduto de gás natural na China, América do Sul e Arábia Saudita.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Função será usada para limpar o texto fornecido, removendo partes indesejadas\n",
        "def limpar(texto):\n",
        "  limpo = re.compile(r'<.*?>') #  Criar um padrão de correspondência. O padrão r'<.*?>' corresponde a qualquer texto que esteja dentro de tags HTML,\n",
        "  #ou seja, algo que comece com <, tenha qualquer conteúdo entre os símbolos e termine com >.\n",
        "  return re.sub(limpo,'',texto) # Retornar o texto limpo de qualquer um desses símbolos de HTML\n",
        "\n",
        "data.Sentence = data.Sentence.apply(limpar)\n",
        "data.Sentence[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "17pxGpIKChTn",
        "outputId": "2464682e-7b92-484c-d8e6-9c3d0a59385d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Os pedidos de produtos de processo são para a instalação de equipamentos de filtração de separação em três projetos de gasoduto de gás natural na China, América do Sul e Arábia Saudita.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para remover caracteres especiais\n",
        "def especial(texto):\n",
        "  rem = '' #  variável rem como uma string vazia\n",
        "  for i in texto: # loop for que percorre cada caractere individual (i) no texto\n",
        "    if i.isalnum(): #  Retorna True se o caractere for uma letra ou um número\n",
        "      rem = rem + i # Se o caractere for alfanumérico (letra ou número), ele é adicionado à string rem\n",
        "    else:\n",
        "      rem = rem + ' '\n",
        "  return rem\n",
        "\n",
        "data.Sentence = data.Sentence.apply(especial)\n",
        "data.Sentence[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "B1Xslo6zCi1n",
        "outputId": "bdf7e328-4ce0-4fa1-848d-58c5acf447c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Os pedidos de produtos de processo são para a instalação de equipamentos de filtração de separação em três projetos de gasoduto de gás natural na China  América do Sul e Arábia Saudita '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converter pra minúsculas\n",
        "def minusculo(texto):\n",
        "  return texto.lower()\n",
        "\n",
        "data.Sentence = data.Sentence.apply(lambda x: x.lower())\n",
        "data.Sentence[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "k8Y4STHRCllm",
        "outputId": "dfa507f2-3d80-4c72-f598-9174394e5b0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'os pedidos de produtos de processo são para a instalação de equipamentos de filtração de separação em três projetos de gasoduto de gás natural na china  américa do sul e arábia saudita '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Limpeza do dataset usando o nltk\n",
        "nltk.download('stopwords') # Faz o download da lista de palavras de stopwords do NLTK, que são palavras comuns como 'de', 'a', 'o' que geralmente não agregam valor\n",
        "nltk.download('punkt') # Faz o download de dados para a função de tokenização de palavras, que divide frases em palavras individuais\n",
        "from nltk.tokenize import word_tokenize # Importa a função de tokenização que quebra o texto em palavras individuais (tokens)\n",
        "\n",
        "def rem_stopwords(texto):\n",
        "  stop_words = set(stopwords.words('portuguese')) # Obtém a lista de stopwords em português e as armazena em um conjunto\n",
        "  words = word_tokenize(texto) # Usa o word_tokenize para quebrar o texto em uma lista de palavras (tokens)\n",
        "  return [w for w in words if w not in stop_words] # Retorna uma lista de palavras filtrada, removendo as stopwords.\n",
        "\n",
        "data.Sentence = data.Sentence.apply(rem_stopwords)\n",
        "data.Sentence[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoHCpGcSCnI5",
        "outputId": "50499cc8-ce9e-4bdc-b5e3-2e59b36a49d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pedidos',\n",
              " 'produtos',\n",
              " 'processo',\n",
              " 'instalação',\n",
              " 'equipamentos',\n",
              " 'filtração',\n",
              " 'separação',\n",
              " 'três',\n",
              " 'projetos',\n",
              " 'gasoduto',\n",
              " 'gás',\n",
              " 'natural',\n",
              " 'china',\n",
              " 'américa',\n",
              " 'sul',\n",
              " 'arábia',\n",
              " 'saudita']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stem_txt(texto):\n",
        "  ss = SnowballStemmer('portuguese') # Cria um objeto stemmer para a língua portuguesa usando o algoritmo Snowball Stemmer\n",
        "  return ' '.join([ss.stem(palavra) for palavra in texto]) # Aplica o stemming em cada palavra do texto e une-as de volta em uma string\n",
        "\n",
        "data.Sentence = data.Sentence.apply(stem_txt)\n",
        "data.Sentence[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "hWEey1QiCpVI",
        "outputId": "6f2dabd9-bbfb-4d7e-a0b1-bbd760a2d88d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ped produt process instal equip filtraçã separ três projet gasodut gás natural chin amér sul aráb saudit'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(data.iloc[:,0].values) # Extrai todos os valores da primeira coluna do DataFrame data usando o .iloc\n",
        "y = np.array(data.Sentiment.values) # Extrai os valores da coluna Sentiment do DataFrame data, que contém os rótulos que tentaremos prever\n",
        "cv = CountVectorizer(max_features=1000) # Ferramenta do sklearn usada para converter uma coleção de documentos de texto em uma matriz de Bag of Words\n",
        "X = cv.fit_transform(data.Sentence).toarray() # Aplica a transformação CountVectorizer na coluna Sentence do DataFrame\n",
        "print('X.shape = ', X.shape)\n",
        "print('y.shape = ', y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8bCK_K0CrKp",
        "outputId": "77b1c4b7-daeb-4fb5-acb0-74b55c06742d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X.shape =  (2996, 1000)\n",
            "y.shape =  (2996,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IM6IEAGeCwgM",
        "outputId": "e1c3b4ea-8dd7-4042-94a4-8ac31d1f7009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar test split\n",
        "# Dividir os dados em conjuntos de treino e teste\n",
        "trainx, textx, trainy, testy = train_test_split(X, y, test_size=0.2, random_state=9)\n",
        "print('Train shapes : X = {}, y = {}' .format(trainx.shape, trainy.shape)) #  Exibe as dimensões do conjunto de treino\n",
        "print('Test shapes : X = {}, y = {}' .format(textx.shape, testy.shape)) # # Exibe as dimensões do conjunto de teste"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtEHQQDdCyIq",
        "outputId": "5204e260-b7a6-4b03-d6e7-0450ccc6ba2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shapes : X = (2396, 1000), y = (2396,)\n",
            "Test shapes : X = (600, 1000), y = (600,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criando o Modelo - Bag of Words"
      ],
      "metadata": {
        "id": "FxVUcKihCtHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir os modelos e treiná-los\n",
        "# Modelo Naive Bayes Gaussiano, adequado para dados contínuos e assume que as características seguem uma distribuição normal.\n",
        "# Modelo Naive Bayes Multinomial, adequado para dados categóricos e texto\n",
        "# Modelo Naive Bayes Bernoulli, adequado para dados binários ou booleanos;\n",
        "gnb, mnb, bnb = GaussianNB(), MultinomialNB(alpha=1.0, fit_prior=True), BernoulliNB(alpha=1.0, fit_prior=True)\n",
        "gnb.fit(trainx, trainy) # Treina o modelo GaussianNB com o conjunto de treino (features e rótulos)\n",
        "mnb.fit(trainx, trainy) # Treina o modelo MultinomialNB com o conjunto de treino\n",
        "bnb.fit(trainx, trainy) # Treina o modelo BernoulliNB com o conjunto de treino"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "ukDHHSX-Czu5",
        "outputId": "f941d84b-a845-459f-ae60-077cd26da24a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BernoulliNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predição e acurácia para escolher o melhor modelo\n",
        "# Realiza previsões no conjunto de teste usando cada um dos modelos treinados\n",
        "ypg = gnb.predict(textx)\n",
        "ypm = mnb.predict(textx)\n",
        "ypb = bnb.predict(textx)"
      ],
      "metadata": {
        "id": "1r1XCRZqC1OP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar qual possui mairo acurácia, quanto mais próximo de 1 melhor\n",
        "print('Guassiana = ', accuracy_score(testy, ypg))\n",
        "print('Multinomial = ', accuracy_score(testy, ypm))\n",
        "print('Bernoulli = ', accuracy_score(testy, ypb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0yZQgqZC2nE",
        "outputId": "3888a202-bfb6-4ec7-c4d1-01736b2cd150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Guassiana =  0.54\n",
            "Multinomial =  0.645\n",
            "Bernoulli =  0.6516666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(bnb, open('model.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "bB4dKbVtC4FR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ler_arquivo():\n",
        "    nome_arquivo = input(\"Digite o nome do arquivo .txt: \")\n",
        "    rev = \"\"  # Inicializa a variável rev como uma string vazia\n",
        "\n",
        "    try:\n",
        "        with open(nome_arquivo, 'r') as arquivo:\n",
        "            rev = arquivo.read()\n",
        "    except FileNotFoundError:\n",
        "        print(f\"O arquivo '{nome_arquivo}' não foi encontrado.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Ocorreu um erro ao ler o arquivo: {e}\")\n",
        "\n",
        "    return rev\n",
        "\n",
        "# Chamando a função e utilizando o valor retornado\n",
        "conteudo_do_arquivo = ler_arquivo()\n",
        "print(\"O conteúdo do arquivo é:\", conteudo_do_arquivo)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3fPtiK9C5w8",
        "outputId": "d83ad919-bf67-463a-81c7-becb2ffe313c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Digite o nome do arquivo .txt: 2874830.txt\n",
            "O conteúdo do arquivo é:  Oi, bom dia, falo com o Sr. Pedro? Bom dia, sou eu mesmo. Sr. Pedro, me chamo Beatriz, falo da TOTS, tudo bem? Da TOTS? Isso. Certo. Tudo bem, Sr. Pedro? Tudo bom, é? Que bom. O Sr. seria o responsável ainda pelo DP e utiliza o sistema na empresa Complexo Brasil? Sim, o responsável pelo DP é a Ana Carla. O Sr. seria pelo RH? Porque pra mim aqui tá como um DP, o Sr. É, mas o responsável no DP é a Ana Carla. Ah, entendi. O Sr. não seria responsável então? Não, eu trabalho com o sistema, sim, ajudo, faz as foras de pagamento, mas a coordenadora é a Ana Carla. Ah, entendi. É que eu preciso fazer um acompanhamento com o responsável pra gente saber como que tá aí a experiência de vocês. Será que ela tem dois minutinhos pra falar comigo agora? É a Ana Carla, né? É a Ana Carla. Tá bom. A Ana Carla da TOTS. Vou transmitir pra ela, 47-06. Obrigada. Ok. R.H. Ana Carla. Bom dia, Ana Carla. Beatriz da TOTS falando, tudo bem? Bom dia, Beatriz. Tudo bem você? Tudo bem, obrigada. A Sara Ana Carla seria responsável pela área e utiliza o sistema TOTS na empresa? Isso. Condomínio do Bloco C, do Brasil, 21, né? Tá. Meu contato é bem rápido, Sara Ana. Eu preciso fazer um acompanhamento só pra saber como tá aí a experiência e satisfação de vocês? Sim. A Sara Ana, eu preciso fazer um acompanhamento só pra saber como tá aí a experiência e satisfação de vocês? Esse acompanhamento é feito pelo método de NPS, então a Sara vai ler somente de 0 a 10 a marca TOTS e alguns pontos específicos que eu preciso perguntar. Dura dois minutinhos, tá bom? Tá ok. Só confirmando então, CNPJ, é o 07354754, meu contra é 99, ok? Então, na verdade é o do Bloco C? Isso, esse eu tô falando em relação ao Bloco C do Brasil, 21, tá? Tá, é porque aqui eu cuido com... Tem outros CNPJ, esse é um que eu não mexo. Ah, entendi, mas a Sara utiliza o sistema. Eu utilizo. Tá, não tem problema, tá bom? O e-mail que eu tenho aqui só pra confirmar, Dara, é o dpbr.com.br, seria a senhora também? Não. Oh, seria da senhora? Não. O meu é Ana Carro, ponto Pereira, da Arroba Melha. Ah, entendi, então vou deixar esses aqui. Eu tenho os dois, aí eu atualizo o comando assim. Obrigada pela atualização. Numa escala de 0 a 10, Sara Ana, qual a probabilidade da Sara recomendar a TOTS, ó amiga ou colega hoje? 10. Tem algum comentário que a Sara gostaria de deixar sobre a nota? Não, o sistema é muito completo, muito bom, eu gosto dele. O sistema é muito completo, tá. Algo mais? Não. Tá, pra gente aprofundar um pouquinho mais na melhoria, agora eu vou falar alguns pontos específicos e peço que a Sara Valir também somente 0 a 10 caso tenha contato, se não tiver, não precisa avaliar, tá bom? Falando do suporte técnico, como a Sara Valir a agilidade quando vocês precisam de um atendimento do suporte? Desculpa, como é que se chama? Beatriz. Beatriz, 6. 6, tá. E o atendimento do agente do suporte, né, os analistas em geral que lidam com vocês? A gente tem uma pessoa específica aqui só, né? Eu continuo 6. É difícil nosso contato. Tá bom. Tá bom. Falando em relação ao atendimento do comercial referente ao Executivo de Vendas, né? Esse eu não tenho contato. Não, tudo bem. Custo e valor dos produtos contratados? A Sara tem contato. Atendimento da administração financeira o referente a boletos e negociações caso precisem? Também não mexo. Satisfação com a implantação do software? A Sara estava quando o sistema foi implantado ou não? Não, tava não. Hoje o sistema entrega o benefício que vocês precisam? Entrega totalmente, parcialmente ou não entrega? Entrega totalmente. Tá. Como foi a experiência da senhora com a atualização do software? Vocês já atualizaram? A Sara como usuária final sente alguma diferença? Não, não. Não, não atualização não é a gente que faz aqui. Mas a Sara como usuária final tem ciência que foi atualizada e sente alguma diferença? Tem, tem. Tá. Então a Sara consegue avaliar de 0 a 10? 9? 9, tá. Para finalizar a PESCA a Sara vai ler de 0 a 10 o atendimento realizado pela TOTUS Unidade de Brasília, é responsável aí por vocês. O atendimento deles. 7. Tá. Sabe se as perguntas a Sara tem algum comentário final, Farahana? Não, não. Tá bom, esse acompanhamento ele ocorre a cada 6 meses, tá? Passando o período retornamos o contato. A Sara tem alguma dúvida, algum comentário final? Não, não, obrigada. Tá. Teria alguma empresa aqui que gostaria de indicar para a gente? No momento não, não me recordo. Tá. Tudo bem, então eu agradeço que a Sara tenha um ótimo dia e bom trabalho, Sara Ana. Tchau, tchau. Obrigada.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar as funções de pré-processamento no conteúdo do arquivo\n",
        "f1 = limpar(conteudo_do_arquivo) # Remove as tags HTML do texto usando a função 'limpar' criada anteriormente\n",
        "f2 = especial(f1) # Remove caracteres especiais, mantendo apenas caracteres alfanuméricos e espaços.\n",
        "f3 = minusculo(f2) # Converte o texto para minúsculas\n",
        "f4 = rem_stopwords(f3) # Remove as stopwords (palavras comuns que não agregam muito significado) do texto\n",
        "f5 = stem_txt(f4) # Aplica stemming, reduzindo palavras às suas raízes\n",
        "\n",
        "# Criar a bolsa de palavras (bag of words) a partir do texto pré-processado\n",
        "bow, words = [], word_tokenize(f5) # Tokeniza o texto\n",
        "for word in words:\n",
        "  bow.append(words.count(word)) # Conta a frequência de cada palavra e adiciona ao 'bow'.\n",
        "\n",
        "# Salvar o dicionário de palavras (vocabulario) em um arquivo usando pickle\n",
        "word_dict = cv.vocabulary_ # Obtém o dicionário de palavras\n",
        "pickle.dump(word_dict, open('bow.pk1', 'wb')) # Serializa o dicionário de palavras e salva em 'bow.pk1'\n",
        "\n",
        "inp = [] # Preparar o vetor de entrada para o modelo\n",
        "for i in word_dict:\n",
        "  inp.append(f5.count(i[0])) # Conta a ocorrência de cada palavra do dicionário no texto pré-processado\n",
        "\n",
        "# Fazer a previsão com o modelo treinado\n",
        "y_pred = bnb.predict(np.array(inp).reshape(1, -1)) # Usa o modelo BernoulliNB para prever, pois tinha melhor acurácia\n",
        "# Use reshape(1, -1) para calcular automaticamente o número de colunas baseadas no array inputado\n",
        "# Printar o resultado final da previsão de sentimentos\n",
        "print(\"O arquivo escolhido para análise de sentimento apresenta um sentimento:\", y_pred)"
      ],
      "metadata": {
        "id": "MDFK4jWAI711",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c39de286-ad9e-4c8f-8926-65f27d8838e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O arquivo escolhido para análise de sentimento apresenta um sentimento: ['neutral']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extração das Notas para um Dataset"
      ],
      "metadata": {
        "id": "sJfh2uqoQEg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar as bibliotecas necessárias\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDH6aBbFl2FJ",
        "outputId": "45b2c3d0-1a0c-4f9e-e665-3986a64e3fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A biblioteca Transformers é uma poderosa e popular ferramenta de código aberto desenvolvida pela empresa Hugging Face. Ela fornece acesso a modelos de aprendizado profundo de última geração baseados na arquitetura Transformer, que são amplamente usados em várias tarefas de processamento de linguagem natural (NLP)"
      ],
      "metadata": {
        "id": "OR2e_Lqv4rW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar a biblioteca\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "Va_maOX-l-15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função ajustada para extrair notas via Regular Expressions\n",
        "def extrair_notas_apos_interrogacao_ajustada(transcricao):\n",
        "    \"\"\"\n",
        "    Função para extrair a primeira nota (número entre 0 e 10) que aparece após uma interrogação \"?\",\n",
        "    ou números seguidos de um ponto final \".\" que aparecem isolados após uma frase,\n",
        "    ou que seguem o termo \"nota\".\n",
        "    Ignora números seguidos diretamente de uma interrogação \"?\",\n",
        "    bem como números irrelevantes como CNPJ, expressões \"0 a 10\", \"0 a 10?\", \"0 a 10,\" e números\n",
        "    no formato \"01\", \"02\", ..., \"09\", ou números maiores que 10 como 27.\n",
        "    Também ignora números que aparecem antes da palavra \"pergunta\" ou \"perguntas\", e ignora \"6 meses\" ou qualquer número seguido de \"meses\".\n",
        "    Considera apenas um número se ele aparecer repetido consecutivamente, como em \"9. 9.\".\n",
        "    \"\"\"\n",
        "    # Remover expressões \"0 a 10\", \"0 a 10?\", \"0 a 10,\" e \"CNPJ\" e números irrelevantes (números longos com mais de 2 dígitos)\n",
        "    transcricao_limpa = re.sub(r\"0\\s*a\\s*10[\\?,\\s]?\", \"\", transcricao)\n",
        "    transcricao_limpa = re.sub(r\"CNPJ|[0-9]{3,}\", \"\", transcricao_limpa)\n",
        "\n",
        "    # Remover números seguidos por \"?\" (ex.: \"9?\") e remover números maiores que 10 (preservando o \"10\")\n",
        "    transcricao_limpa = re.sub(r'\\b\\d+\\?\\b', '', transcricao_limpa)\n",
        "    transcricao_limpa = re.sub(r'\\b(?!10\\b)\\d{2,}\\b', '', transcricao_limpa)  # Remove números maiores que 10, mas preserva 10\n",
        "\n",
        "    # Remover números no formato \"01\", \"02\", ..., \"09\"\n",
        "    transcricao_limpa = re.sub(r'\\b0[1-9]\\b', '', transcricao_limpa)\n",
        "\n",
        "    # Remover números que aparecem antes das palavras \"pergunta\" ou \"perguntas\"\n",
        "    transcricao_limpa = re.sub(r'\\b\\d+\\s*(pergunta|perguntas)\\b', '', transcricao_limpa, flags=re.IGNORECASE)\n",
        "\n",
        "    # Remover números seguidos da palavra \"meses\" (ex.: \"6 meses\")\n",
        "    transcricao_limpa = re.sub(r'\\b\\d+\\s*meses\\b', '', transcricao_limpa, flags=re.IGNORECASE)\n",
        "\n",
        "    # Capturar números seguidos por ponto final após uma frase (ex.: \"O atendimento deles. 9. 9.\")\n",
        "    notas_com_ponto_final = re.findall(r'\\.\\s*(\\d+)\\.', transcricao_limpa)\n",
        "\n",
        "    # Capturar números que vêm após o termo \"nota \" (ex.: \"nota 7\")\n",
        "    notas_apos_termo_nota = re.findall(r'nota\\s*(\\d+)', transcricao_limpa)\n",
        "\n",
        "    # Incluir números seguidos de ponto (ex.: \"7.\") e tratá-los como notas válidas\n",
        "    transcricao_limpa = re.sub(r'(\\b\\d+)\\.', r'\\1', transcricao_limpa)\n",
        "\n",
        "    # Dividir a transcrição em partes com base na presença de \"?\"\n",
        "    partes = re.split(r'\\?', transcricao_limpa)\n",
        "\n",
        "    notas = []\n",
        "\n",
        "    # Iterar sobre as partes após cada interrogação\n",
        "    for parte in partes[1:]:  # Ignorar o que vem antes da primeira \"?\"\n",
        "        # Procurar o primeiro número após a interrogação\n",
        "        match = re.search(r'\\b\\d+\\b', parte)\n",
        "        if match:\n",
        "            nota = int(match.group())\n",
        "            if 0 <= nota <= 10 and (not notas or notas[-1] != nota):  # Apenas números entre 0 e 10, sem duplicatas consecutivas\n",
        "                notas.append(nota)\n",
        "\n",
        "    # Adicionar as notas capturadas no padrão \"O atendimento deles. 9. 9.\" e remover duplicatas consecutivas\n",
        "    for i, nota in enumerate(notas_com_ponto_final):\n",
        "        if i == 0 or int(nota) != int(notas_com_ponto_final[i - 1]):  # Evitar duplicatas consecutivas\n",
        "            nota = int(nota)\n",
        "            if 0 <= nota <= 10:\n",
        "                notas.append(nota)\n",
        "\n",
        "    # Adicionar as notas capturadas após o termo \"nota\"\n",
        "    for nota in notas_apos_termo_nota:\n",
        "        nota = int(nota)\n",
        "        if 0 <= nota <= 10 and (not notas or notas[-1] != nota):  # Evitar duplicatas consecutivas\n",
        "            notas.append(nota)\n",
        "\n",
        "    return notas\n",
        "\n",
        "# Inicializar uma lista para armazenar todas as listas de notas extraídas\n",
        "todas_as_listas_de_notas = []\n",
        "\n",
        "while True:\n",
        "    # Pedir o nome do arquivo .txt como input do usuário\n",
        "    nome_arquivo = input(\"Digite o nome do arquivo .txt (com extensão): \")\n",
        "\n",
        "    # Ler o conteúdo do arquivo fornecido pelo usuário\n",
        "    try:\n",
        "        with open(nome_arquivo, 'r', encoding='utf-8') as f:\n",
        "            nova_transcricao = f.read()\n",
        "\n",
        "        # Processamento da transcrição com a função ajustada\n",
        "        notas_ajustadas_nova_transcricao = extrair_notas_apos_interrogacao_ajustada(nova_transcricao)\n",
        "\n",
        "        # Adicionar as notas extraídas à lista de todas as listas de notas\n",
        "        todas_as_listas_de_notas.append(notas_ajustadas_nova_transcricao)\n",
        "\n",
        "        # Calcular a média das notas para este arquivo\n",
        "        if notas_ajustadas_nova_transcricao:\n",
        "            media_nps = np.mean(notas_ajustadas_nova_transcricao)\n",
        "        else:\n",
        "            media_nps = np.nan  # Ou você pode definir como 0 ou outro valor padrão\n",
        "\n",
        "        # Imprimir as notas e a média para este arquivo\n",
        "        print(f\"\\nlista_notas = {notas_ajustadas_nova_transcricao}\")\n",
        "        print(f\"media_nps = {media_nps}\\n\")\n",
        "\n",
        "        # Perguntar se o usuário deseja processar outro arquivo\n",
        "        continuar = input(\"Deseja processar outro arquivo? (sim/não): \").strip().lower()\n",
        "        if continuar != 'sim':\n",
        "            break\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"O arquivo '{nome_arquivo}' não foi encontrado. Verifique o nome e tente novamente.\")\n",
        "\n",
        "# Encontrar o número máximo de notas entre todas as listas\n",
        "max_len = max(len(lista) for lista in todas_as_listas_de_notas) if todas_as_listas_de_notas else 0\n",
        "\n",
        "if max_len > 0:\n",
        "    # Preencher as listas menores com valores NaN para que todas as listas tenham o mesmo comprimento\n",
        "    listas_alinhadas = [lista + [np.nan] * (max_len - len(lista)) for lista in todas_as_listas_de_notas]\n",
        "\n",
        "    # Criar um DataFrame onde cada coluna será uma \"nota 1\", \"nota 2\", etc.\n",
        "    df = pd.DataFrame(listas_alinhadas, columns=[f\"nota {i+1}\" for i in range(max_len)])\n",
        "\n",
        "    # Calcular a média das notas para cada linha, ignorando NaN\n",
        "    df['media_nps'] = df.mean(axis=1, skipna=True)\n",
        "\n",
        "    # Exibir o DataFrame resultante\n",
        "    print(\"DataFrame com todas as notas e médias:\")\n",
        "    print(df)\n",
        "else:\n",
        "    print(\"Nenhuma nota foi extraída dos arquivos fornecidos.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ED0kvjkZ-DrS",
        "outputId": "72de1b54-274d-4ef6-a991-22bcfdd0ae68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Digite o nome do arquivo .txt (com extensão): 2874830.txt\n",
            "\n",
            "lista_notas = [10, 6, 9, 7]\n",
            "media_nps = 8.0\n",
            "\n",
            "Deseja processar outro arquivo? (sim/não): sim\n",
            "Digite o nome do arquivo .txt (com extensão): 2962046.txt\n",
            "\n",
            "lista_notas = [8, 6, 7, 6, 8, 7, 6]\n",
            "media_nps = 6.857142857142857\n",
            "\n",
            "Deseja processar outro arquivo? (sim/não): não\n",
            "DataFrame com todas as notas e médias:\n",
            "   nota 1  nota 2  nota 3  nota 4  nota 5  nota 6  nota 7  media_nps\n",
            "0      10       6       9       7     NaN     NaN     NaN   8.000000\n",
            "1       8       6       7       6     8.0     7.0     6.0   6.857143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "GScpaZsWbP45",
        "outputId": "b7c6de28-af4f-4dc6-dbb5-986a680e9f6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   nota 1  nota 2  nota 3  nota 4  nota 5  nota 6  nota 7  media_nps\n",
              "0      10       6       9       7     NaN     NaN     NaN   8.000000\n",
              "1       8       6       7       6     8.0     7.0     6.0   6.857143"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17ce0716-cc90-4407-b41b-a2d86fad1071\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nota 1</th>\n",
              "      <th>nota 2</th>\n",
              "      <th>nota 3</th>\n",
              "      <th>nota 4</th>\n",
              "      <th>nota 5</th>\n",
              "      <th>nota 6</th>\n",
              "      <th>nota 7</th>\n",
              "      <th>media_nps</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.857143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17ce0716-cc90-4407-b41b-a2d86fad1071')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-17ce0716-cc90-4407-b41b-a2d86fad1071 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-17ce0716-cc90-4407-b41b-a2d86fad1071');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-659b4ece-bebc-450f-9756-1736918d322e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-659b4ece-bebc-450f-9756-1736918d322e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-659b4ece-bebc-450f-9756-1736918d322e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"nota 1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 8,\n        \"max\": 10,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          8,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nota 2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 6,\n        \"max\": 6,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nota 3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 7,\n        \"max\": 9,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nota 4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 6,\n        \"max\": 7,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nota 5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 8.0,\n        \"max\": 8.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          8.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nota 6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 7.0,\n        \"max\": 7.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          7.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nota 7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 6.0,\n        \"max\": 6.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          6.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"media_nps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8081220356417689,\n        \"min\": 6.857142857142857,\n        \"max\": 8.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          6.857142857142857\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar o DataFrame como 'dataset_nps.csv'\n",
        "df.to_csv('dataset_nps.csv', index=False)\n",
        "print(\"\\nO DataFrame foi salvo como 'dataset_nps.csv'.\")"
      ],
      "metadata": {
        "id": "ZjkRvK4Qd3Fy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2befc8fa-8376-4867-f9c3-2ecff5808a7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "O DataFrame foi salvo como 'dataset_nps.csv'.\n"
          ]
        }
      ]
    }
  ]
}